---
label: Test Scenarios
icon: shield
---

# Test Scenarios

Test scenarios are organized into groups, each containing multiple probes targeting specific vulnerabilities. Not every group will be relevant to all applications; it's important first to align your coverage to match the particular risks and attack vectors pertinent to your AI systems. Although the testing framework remains stable, individual probes adapt and evolve continually as new exploits and vulnerabilities emerge.

Scenario groups include:
- Security Vulnerabilities
- Jailbreaks and Filter Bypass
- Content Risks and Harmful Output
- Data Leakage and Memorization
- Coding-Specific Risks
- Linguistic and Behavioral Testing
- Topic Control and Filtering

AI security testing differs significantly from traditional software testing. The attack surface for AI agents is broader because anyone interacting through prompts—users, partners, or even employees—can potentially exploit the system. Unlike traditional applications, where inputs and interfaces can be tightly controlled, AI agents interpret natural language, making every prompt potentially malicious. This inherent openness requires continuous testing rather than one-off assessments.

Teev addresses this by continuously testing your AI apps against the latest known exploits. The platform dynamically adapts its scope, providing visibility into new vulnerabilities and tracking your security posture over time. Probes are regularly updated because adversaries innovate rapidly, creating new attack methods faster than models or static defenses can adapt.

This testing approach complements—not replaces—traditional guardrails, security best practices, and adherence to least-privilege principles. By using Teev, teams can proactively identify and mitigate risks, ensuring that your AI applications remain secure, trustworthy, and resilient against evolving threats.

